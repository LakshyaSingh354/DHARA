{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(file):\n",
    "    prompt = f'''{file} \\n please go through the above case in complete detail and provide me a contextual summary of the case, A summary of the relevant legal information.\\nI want large data. give large contextual summary full detailed case by going through the whole txt file. give proper detailed info of what all happened in the case arguments by appealant, responsdent, judge decisions, etc etc,\\nI want everything in detail. all the facts in the case, all relevant sections in the file, all legal principles in the file, each and every cotext in the file \\n \\n \n",
    "    Follow this template for all the summaries like a bible:\\n \n",
    "    1. Case Title\n",
    "\n",
    "\t•\tCase Name: [e.g., ABC Corp. vs. XYZ Ltd.]\n",
    "\t•\tCourt: [e.g., Supreme Court of India]\n",
    "\t•\tDate of Judgment: [e.g., 23rd August 2024]\n",
    "\t•\tCitation: [e.g., 2024 SCC 123]\n",
    "\n",
    "2. Background and Context\n",
    "\n",
    "\t•\tBrief Overview: A concise summary of the case background, including relevant events leading up to the legal dispute.\n",
    "\t•\tKey Issues: A list of the main legal questions or issues presented in the case.\n",
    "\n",
    "3. Legal Principles Involved\n",
    "\n",
    "\t•\tRelevant Statutes and Provisions: List of statutory provisions, rules, and regulations relevant to the case.\n",
    "\t•\tPrecedents Cited: Key past judgments cited during the case.\n",
    "\t•\tLegal Doctrines: Any specific legal doctrines or principles applied in the judgment.\n",
    "\n",
    "4. Arguments Presented\n",
    "\n",
    "\t•\tPlaintiff’s Argument: Summary of the arguments and claims made by the plaintiff.\n",
    "\t•\tDefendant’s Argument: Summary of the arguments and defenses presented by the defendant.\n",
    "\n",
    "5. Court’s Analysis and Reasoning\n",
    "\n",
    "\t•\tKey Findings: Important observations and findings made by the court.\n",
    "\t•\tInterpretation of Law: How the court interpreted the relevant legal provisions and precedents.\n",
    "\t•\tApplication of Law: How the court applied the law to the facts of the case.\n",
    "\n",
    "6. Judgment\n",
    "\n",
    "\t•\tFinal Decision: The outcome of the case (e.g., in favor of the plaintiff/defendant).\n",
    "\t•\tRelief Granted: Any relief or damages awarded, if applicable.\n",
    "\t•\tOrders: Specific orders or directives issued by the court.\n",
    "\n",
    "7. Implications\n",
    "\n",
    "\t•\tImpact on Law: How the judgment impacts existing law or legal practice.\n",
    "\t•\tFuture Relevance: The potential influence of the case on future legal decisions or cases.\n",
    "\t•\tBroader Context: Any broader implications, such as social, economic, or political impact.\n",
    "\n",
    "8. Summary Points\n",
    "\n",
    "\t•\tKey Takeaways: Bullet points summarizing the most critical aspects of the case, suitable for quick reference.\n",
    "\n",
    "9. References\n",
    "\n",
    "\t•\tCitations: Full citations of any statutes, cases, or legal texts referenced in the summary.\n",
    "\t•\tFurther Reading: Suggestions for further reading or related cases.'''\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_data(file):\n",
    "    prompt = f\"\"\"{file} \\n\n",
    "    Above is the case file. I want you to go through the same in detail and provide me the below reponse in json format. \n",
    "    Make sure to provide as much data as possible available in the file. Give me 10 queries with the following fields in a Json ARRAY with 10 different JSON objects (Make sure to follow this format).\n",
    "    Query: A natural language query representing a typical legal research question.(Here the judge will eneter the present case for which the model will search in database)(The query can be the whole present case that judge wants to solve).\n",
    "# \t•\tLegal Principles: Key legal principles or precedents related to the query.\n",
    "# \t•\tRelevant Sections: Extracted and highlighted sections from the relevant documents.\n",
    "# \t•\tContext: Additional information about the legal context (e.g., jurisdiction, case type) that can be used to fine-tune the model's response.\n",
    "# The Query should be an actual present case that a jusdge wants to solve. A one or 2 line description of the case over which the judge is currently presiding on. \n",
    "#  Make sure to create some imaginary case (not the same one provided above) for the queries\"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"data\")\n",
    "print(files)\n",
    "\n",
    "for file in tqdm(files[:2], desc=\"Generating Summaries: \"):\n",
    "    text = open(f'data/{file}', 'r').read()\n",
    "    summary = generate_summary(text)\n",
    "    with open(f\"case_summary{file}\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(f'data/{file}','r', encoding=\"utf-8\").read()\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['case1.txt', 'case10.txt', 'case100.txt', 'case101.txt', 'case102.txt', 'case103.txt', 'case104.txt', 'case105.txt', 'case106.txt', 'case107.txt', 'case108.txt', 'case109.txt', 'case11.txt', 'case110.txt', 'case111.txt', 'case112.txt', 'case113.txt', 'case114.txt', 'case115.txt', 'case116.txt', 'case117.txt', 'case118.txt', 'case119.txt', 'case12.txt', 'case120.txt', 'case121.txt', 'case122.txt', 'case123.txt', 'case124.txt', 'case125.txt', 'case126.txt', 'case127.txt', 'case128.txt', 'case129.txt', 'case13.txt', 'case130.txt', 'case131.txt', 'case132.txt', 'case133.txt', 'case134.txt', 'case135.txt', 'case136.txt', 'case137.txt', 'case138.txt', 'case139.txt', 'case14.txt', 'case140.txt', 'case141.txt', 'case142.txt', 'case143.txt', 'case144.txt', 'case145.txt', 'case146.txt', 'case147.txt', 'case148.txt', 'case149.txt', 'case15.txt', 'case150.txt', 'case151.txt', 'case152.txt', 'case153.txt', 'case154.txt', 'case155.txt', 'case156.txt', 'case157.txt', 'case158.txt', 'case159.txt', 'case16.txt', 'case160.txt', 'case161.txt', 'case162.txt', 'case163.txt', 'case164.txt', 'case165.txt', 'case166.txt', 'case167.txt', 'case168.txt', 'case169.txt', 'case17.txt', 'case170.txt', 'case171.txt', 'case172.txt', 'case173.txt', 'case174.txt', 'case175.txt', 'case176.txt', 'case177.txt', 'case178.txt', 'case179.txt', 'case18.txt', 'case180.txt', 'case181.txt', 'case182.txt', 'case183.txt', 'case184.txt', 'case185.txt', 'case186.txt', 'case187.txt', 'case188.txt', 'case189.txt', 'case19.txt', 'case190.txt', 'case191.txt', 'case192.txt', 'case193.txt', 'case194.txt', 'case195.txt', 'case196.txt', 'case197.txt', 'case198.txt', 'case199.txt', 'case2.txt', 'case20.txt', 'case200.txt', 'case201.txt', 'case202.txt', 'case203.txt', 'case204.txt', 'case205.txt', 'case206.txt', 'case207.txt', 'case208.txt', 'case209.txt', 'case21.txt', 'case210.txt', 'case211.txt', 'case212.txt', 'case213.txt', 'case214.txt', 'case215.txt', 'case216.txt', 'case217.txt', 'case218.txt', 'case219.txt', 'case22.txt', 'case220.txt', 'case221.txt', 'case222.txt', 'case223.txt', 'case224.txt', 'case225.txt', 'case226.txt', 'case227.txt', 'case228.txt', 'case229.txt', 'case23.txt', 'case230.txt', 'case231.txt', 'case232.txt', 'case233.txt', 'case234.txt', 'case235.txt', 'case236.txt', 'case237.txt', 'case238.txt', 'case239.txt', 'case24.txt', 'case240.txt', 'case241.txt', 'case242.txt', 'case243.txt', 'case244.txt', 'case245.txt', 'case246.txt', 'case247.txt', 'case248.txt', 'case249.txt', 'case25.txt', 'case250.txt', 'case251.txt', 'case252.txt', 'case253.txt', 'case254.txt', 'case255.txt', 'case256.txt', 'case257.txt', 'case258.txt', 'case259.txt', 'case26.txt', 'case260.txt', 'case261.txt', 'case262.txt', 'case263.txt', 'case264.txt', 'case265.txt', 'case266.txt', 'case267.txt', 'case268.txt', 'case269.txt', 'case27.txt', 'case270.txt', 'case271.txt', 'case272.txt', 'case273.txt', 'case274.txt', 'case275.txt', 'case276.txt', 'case277.txt', 'case278.txt', 'case279.txt', 'case28.txt', 'case280.txt', 'case281.txt', 'case282.txt', 'case283.txt', 'case284.txt', 'case285.txt', 'case286.txt', 'case287.txt', 'case288.txt', 'case289.txt', 'case29.txt', 'case290.txt', 'case291.txt', 'case292.txt', 'case293.txt', 'case294.txt', 'case295.txt', 'case296.txt', 'case297.txt', 'case298.txt', 'case299.txt', 'case3.txt', 'case30.txt', 'case300.txt', 'case301.txt', 'case302.txt', 'case303.txt', 'case304.txt', 'case305.txt', 'case306.txt', 'case307.txt', 'case308.txt', 'case309.txt', 'case31.txt', 'case310.txt', 'case311.txt', 'case312.txt', 'case313.txt', 'case314.txt', 'case315.txt', 'case316.txt', 'case317.txt', 'case318.txt', 'case319.txt', 'case32.txt', 'case320.txt', 'case321.txt', 'case322.txt', 'case323.txt', 'case324.txt', 'case325.txt', 'case326.txt', 'case327.txt', 'case328.txt', 'case329.txt', 'case33.txt', 'case330.txt', 'case331.txt', 'case332.txt', 'case333.txt', 'case334.txt', 'case335.txt', 'case336.txt', 'case337.txt', 'case338.txt', 'case339.txt', 'case34.txt', 'case340.txt', 'case341.txt', 'case342.txt', 'case343.txt', 'case344.txt', 'case345.txt', 'case346.txt', 'case347.txt', 'case348.txt', 'case349.txt', 'case35.txt', 'case350.txt', 'case351.txt', 'case352.txt', 'case353.txt', 'case354.txt', 'case355.txt', 'case356.txt', 'case357.txt', 'case358.txt', 'case359.txt', 'case36.txt', 'case360.txt', 'case361.txt', 'case362.txt', 'case363.txt', 'case364.txt', 'case365.txt', 'case366.txt', 'case367.txt', 'case368.txt', 'case369.txt', 'case37.txt', 'case370.txt', 'case371.txt', 'case372.txt', 'case373.txt', 'case374.txt', 'case375.txt', 'case376.txt', 'case377.txt', 'case378.txt', 'case379.txt', 'case38.txt', 'case380.txt', 'case381.txt', 'case382.txt', 'case383.txt', 'case384.txt', 'case385.txt', 'case386.txt', 'case387.txt', 'case388.txt', 'case389.txt', 'case39.txt', 'case390.txt', 'case391.txt', 'case392.txt', 'case393.txt', 'case394.txt', 'case395.txt', 'case396.txt', 'case397.txt', 'case398.txt', 'case399.txt', 'case4.txt', 'case40.txt', 'case400.txt', 'case41.txt', 'case42.txt', 'case43.txt', 'case44.txt', 'case45.txt', 'case46.txt', 'case47.txt', 'case48.txt', 'case49.txt', 'case5.txt', 'case50.txt', 'case51.txt', 'case52.txt', 'case53.txt', 'case54.txt', 'case55.txt', 'case56.txt', 'case57.txt', 'case58.txt', 'case59.txt', 'case6.txt', 'case60.txt', 'case61.txt', 'case62.txt', 'case63.txt', 'case64.txt', 'case65.txt', 'case66.txt', 'case67.txt', 'case68.txt', 'case69.txt', 'case7.txt', 'case70.txt', 'case71.txt', 'case72.txt', 'case73.txt', 'case74.txt', 'case75.txt', 'case76.txt', 'case77.txt', 'case78.txt', 'case79.txt', 'case8.txt', 'case80.txt', 'case81.txt', 'case82.txt', 'case83.txt', 'case84.txt', 'case85.txt', 'case86.txt', 'case87.txt', 'case88.txt', 'case89.txt', 'case9.txt', 'case90.txt', 'case91.txt', 'case92.txt', 'case93.txt', 'case94.txt', 'case95.txt', 'case96.txt', 'case97.txt', 'case98.txt', 'case99.txt']\n",
      "Files completed 629/299\n",
      "Completed File: case99.txt\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"data\")\n",
    "print(files)\n",
    "#56 files done\n",
    "# for i, file in enumerate(files[15]):\n",
    "text = open(f'data/case15.txt','r', encoding=\"utf-8\").read()\n",
    "query = structured_data(text)\n",
    "with open(f\"data_json/query_jsoncase15\", \"w\", encoding=\"utf-8\") as outfile:\n",
    "    outfile.write(query)\n",
    "print(f\"Files completed {i+230}/299\")\n",
    "print(f\"Completed File: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_format = '''\n",
    "# \t•\tQuery: A natural language query representing a typical legal research question.\n",
    "# \t•\tRelevant Document IDs: List of document IDs that are relevant to the query.\n",
    "# \t•\tResponse Text: The model’s expected output in response to the query, including:\n",
    "# \t•\tContextual Summary: A summary of the relevant legal information.\n",
    "# \t•\tLegal Principles: Key legal principles or precedents related to the query.\n",
    "# \t•\tRelevant Sections: Extracted and highlighted sections from the relevant documents.\n",
    "# \t•\tContext: Additional information about the legal context (e.g., jurisdiction, case type) that can be used to fine-tune the model’s response.'''\n",
    "\n",
    "# prompt = f'{file} \\n format the data in the following format: \\n {data_format}. Keep in mind that the model will be trained on this data to generate responses to legal research questions. \\n Don\\'t keep the summary too short or too long. \\n'\n",
    "# prompt2 = f'''{file} \\n please go through the above case in complete detail\n",
    "# The thing is I need strucred data for the above model. I need the data in below given format\n",
    "# •⁠  ⁠Query ID: Unique identifier for each query-response pair.\n",
    "# \t•\tQuery: A natural language query representing a typical legal research question(Here the judge will eneter the present case for which the model will search in database)(The query can be the whole present case that judgse wants to solve).\n",
    "# \t•\tRelevant Document IDs: List of document IDs that are relevant to the query.\n",
    "# \t•\tResponse Text: The model’s expected output in response to the query, including:\n",
    "# \t•\tContextual Summary: A summary of the relevant legal information(from the text file).\n",
    "# \t•\tLegal Principles: Key legal principles or precedents related to the query(from text file. legal principles that are used in the previous case i.e. text file).\n",
    "# \t•\tRelevant Sections: Extracted and highlighted sections from the relevant documents(Relevant acts or sections from the previous case gievn in the text file).\n",
    "# \t•\tContext: Additional information about the legal context (e.g., jurisdiction, case type) that can be used to fine-tune the model’s response.\n",
    "# I want large data. give large contextual summary full detailed case by going through the whole txt file. give proper detailed info of what all happened in the case arguments by appealant, responsdent, judge decisions, etc etc,\n",
    "\n",
    "# I want everything in detail. all the facts in the case, all relevant sections in the file, all legal principles in the file, each and every cotext in the file\n",
    "\n",
    "# Please provide your response in JSON format.'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
